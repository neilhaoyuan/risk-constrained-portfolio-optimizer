{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the libraries you can use.  You may add any libraries directy related to threading if this is a direction\n",
    "#you wish to go (this is not from the course, so it's entirely on you if you wish to use threading).  Any\n",
    "#further libraries you wish to use you must email me, james@uwaterloo.ca, for permission.\n",
    "\n",
    "from IPython.display import display, Math, Latex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime\n",
    "import scipy as sp \n",
    "from scipy.optimize import minimize\n",
    "import itertools as itr\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Assignment\n",
    "### Team Number: 15\n",
    "### Team Member Names: Neil Zhang, Rahim Rehan, Krish Patel\n",
    "### Team Strategy Chosen: Risk-Free "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_tickers(csv_file_path):\n",
    "   \"\"\"\n",
    "   valid_tickers is the prelimary checker, it reads a csv and then removes any tickers that trade less than 5000 shares a month\n",
    "\n",
    "   :param csv_file_path: A string that represents the csv file name that will be read\n",
    "   :return: A list of names of the valid tickers\n",
    "   \"\"\"\n",
    "   tickers_df = pd.read_csv(csv_file_path, header=None)\n",
    "   tickers_df.columns = [\"Ticker\"]\n",
    "   ticker_list = tickers_df[\"Ticker\"].tolist()\n",
    "\n",
    "   # Bulk download the ticker information\n",
    "   hist = yf.download(\n",
    "       tickers=ticker_list,\n",
    "       start=\"2024-10-01\",\n",
    "       end=\"2025-10-01\",\n",
    "       group_by=\"ticker\",\n",
    "       auto_adjust=False,\n",
    "       threads=True\n",
    "    )\n",
    "   \n",
    "   # Count rows per month per ticker\n",
    "   counts = hist.groupby(hist.index.to_period(\"M\")).transform(\"count\")\n",
    "\n",
    "   # Keep only rows where all tickers in that month have >= 18 trading days\n",
    "   valid_days = counts >= 18\n",
    "\n",
    "   # Remove the months that do not meet threshold and any tickers that don't have a large enough trading volume\n",
    "   hist_filtered = hist[valid_days]\n",
    "   vol_filtered = hist_filtered.xs(\"Volume\", axis=1, level=1)\n",
    "   avg_vol_filtered = vol_filtered.mean()\n",
    "   valid_tickers = avg_vol_filtered[avg_vol_filtered >= 5000].index.tolist()\n",
    "\n",
    "   return valid_tickers\n",
    "\n",
    "#Begin threading set up\n",
    "def get_format_info(ticker, ticker_data):\n",
    "   \"\"\"\n",
    "   get_format_info is the threading worker function, it is what will be done in parallel. It finds wanted ticker info\n",
    "   and adds it to a list\n",
    "\n",
    "   :param ticker: The ticker whose info is wanted\n",
    "   :param ticker_data: A list that keeps track of the ticker info thats been extracted\n",
    "   \"\"\"\n",
    "   ticker_info = yf.Ticker(ticker).info\n",
    "\n",
    "   # Get the currency, recall we only want USD and CAD traded stocks\n",
    "   currency = ticker_info.get(\"currency\")\n",
    "   if (currency not in [\"USD\", \"CAD\"]):\n",
    "      currency = \"NaN\"\n",
    "\n",
    "   ticker_data.append((ticker, ticker_info.get(\"sector\"), currency, ticker_info.get(\"marketCap\")))\n",
    "\n",
    "#Threading occurs\n",
    "def format_tickers(csv_file_path):\n",
    "   \"\"\"\n",
    "   format_tickers is the main function that performs threading onto the worker function and gets the dataframe of tickers and wanted info\n",
    "\n",
    "   :param csv_file_path: A string that represents the csv file name that will be read\n",
    "   :return: A Dataframe that contains all the info we want for every valid ticker\n",
    "   \"\"\"\n",
    "   ticker_list = valid_tickers(csv_file_path)\n",
    "   \n",
    "   # Threading set up, ticker_data is the shared list where threads store their results, threads is the list of the thread objects\n",
    "   ticker_data = []\n",
    "   threads = []\n",
    "\n",
    "   # Loop and create threads of each ticker in the ticker_list\n",
    "   for t in ticker_list:\n",
    "      thread = Thread(target=get_format_info, args=(t, ticker_data))\n",
    "      threads.append(thread)\n",
    "      thread.start()\n",
    "\n",
    "   # Once all threads complete, join them together \n",
    "   for th in threads:\n",
    "      th.join()\n",
    "\n",
    "   # Create and clean up the Dataframe\n",
    "   ticker_df = pd.DataFrame(ticker_data, columns=[\"Ticker\",\"Sector\",\"Currency\",\"MarketCap\"]) \n",
    "   ticker_df = ticker_df[ticker_df[\"Currency\"] != \"NaN\"]\n",
    "   ticker_df = ticker_df.reset_index(drop=True)\n",
    "   return ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  143 of 143 completed\n",
      "\n",
      "10 Failed downloads:\n",
      "['DFS', 'GIB.A.TO', 'ATVI', 'AGN', 'CELG', 'BRK.B', 'PTR', 'MON', 'ZZZ.TO', 'RTN']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Access each piece like:\\ndisplay(primary_calculations['Covariance'])\\ndisplay(primary_calculations['Std_Dev'])\\n\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Krish, Info Extraction \n",
    "\n",
    "returns_start = \"2024-11-14\"\n",
    "returns_end = \"2025-11-14\"\n",
    "\n",
    "# Function to return a list of all tickers (first column elements)\n",
    "def get_ticker_list (tickers_df):\n",
    "     \"\"\"\n",
    "     get_ticker_list returns a Python list of tickers\n",
    "\n",
    "     :param tickers_df: A Dataframe of tickers\n",
    "     :return: A list of tickers\n",
    "     \"\"\"\n",
    "     return tickers_df.iloc[:, 0].tolist()\n",
    "\n",
    "# Gets weekly closes of all the stocks in a list of tickers\n",
    "def get_weekly_closes (ticker_lst, start_date, end_date):\n",
    "    \"\"\"     \n",
    "    get_weekly_closes performs data extraction to get weekly closing price info of stocks\n",
    "\n",
    "    :param ticker_lst: List that holds all tickers\n",
    "    :param start_date: start date for calculations\n",
    "    :param end_date: end date for calculations\n",
    "    :return: returns a Dataframe that holds the weekly closing price of each ticker on every week\n",
    "    \"\"\"\n",
    "    #Define a dataframe to hold weekly close prices (checks every friday)\n",
    "    cols = [] # list of Series to concat\n",
    "    #Extract the weekly close prices and store them in the dataframe\n",
    "    for i in ticker_lst:\n",
    "        ticker = yf.Ticker(i)\n",
    "        data = ticker.history(start=start_date, end=end_date)\n",
    "        data.index = pd.to_datetime(data.index) # ensure datetime index\n",
    "        #last() takes the last trading price of the week\n",
    "        series = data['Close'].resample('W-FRI').last()\n",
    "        series.name = f\"Close {i}\" # name each column\n",
    "        cols.append(series) # store weekly closes for each ticker\n",
    "        \n",
    "    # Concatenate all ticker series at once to avoid fragmentation\n",
    "    weekly_closes = pd.concat(cols, axis=1)\n",
    "    # Strip time\n",
    "    weekly_closes.index = weekly_closes.index.strftime('%Y-%m-%d')\n",
    "    return weekly_closes\n",
    "\n",
    "# Creates a df with the (weekly) %change for each column\n",
    "def get_percent_change (closes, start_date, end_date):\n",
    "    \"\"\"     \n",
    "    get_percent_change performs calculations that determines the percent change of closing prices\n",
    "\n",
    "    :param closes: Dataframe that holds closing prices\n",
    "    :param start_date: start date for calculations\n",
    "    :param end_date: end date for calculations\n",
    "    :return: returns a Dataframe that holds percent changes of closing prices\n",
    "    \"\"\"\n",
    "    cols = [] # list of Series to concat\n",
    "    \n",
    "    for i in closes:\n",
    "        col_name = i[6:] # name each column by the ticker from \"Close ---\"\n",
    "        # calculate %change\n",
    "        series = closes[i].pct_change(fill_method=None) # Fill_method=None to hande delisted stocks\n",
    "        series.name = f\"% Change {col_name}\" # name each column\n",
    "        cols.append(series) # store %change for each ticker\n",
    "\n",
    "    # Concatenate all ticker series at once to avoid fragmentation\n",
    "    percent_change = pd.concat(cols, axis=1)\n",
    "    return percent_change\n",
    "\n",
    "# Calculate covariance, correlation, variance, standard deviation\n",
    "def get_calculations(ticker_list, start_date, end_date):\n",
    "    \"\"\"     \n",
    "    get_calculations performs calculations for covariance, correlation, variance, standard deviation\n",
    "\n",
    "    :param ticker_list: list of all tickers\n",
    "    :param start_date: start date for calculations\n",
    "    :param end_date: end date for calculations\n",
    "    :return: returns a dictionary that holds covariance, correlation, standard deviation, and variance \n",
    "    \"\"\"\n",
    "    weekly_closes = get_weekly_closes(ticker_list, start_date, end_date)\n",
    "    weekly_percent_change = get_percent_change(weekly_closes, start_date, end_date)\n",
    "    covariance_matrix = {\n",
    "        'Covariance': weekly_percent_change.cov(),\n",
    "        'Correlation': weekly_percent_change.corr(),\n",
    "        'Variance': weekly_percent_change.var(),\n",
    "        'Std_Dev': weekly_percent_change.std()}\n",
    "    return covariance_matrix\n",
    "\n",
    "info_df = format_tickers(\"Extended_Tickers_Example.csv\") #NOTE: CHANGE FILE NAME BEFORE SUBMITTING\n",
    "ticker_list = (get_ticker_list(info_df)) # List of all tickers\n",
    "primary_calculations = get_calculations(ticker_list, returns_start, returns_end) # Covariance matrix\n",
    "\"\"\"\n",
    "# Access each piece like:\n",
    "display(primary_calculations['Covariance'])\n",
    "display(primary_calculations['Std_Dev'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neil opimization models \n",
    "# This is the function we want to minimize, aka the minimum variance function\n",
    "def port_variance(weights, cov_matrix):\n",
    "    \"\"\"     \n",
    "    port_variance is the function that calculates the variance of a portfolio. It performs \n",
    "    dot product/matrix multiplication on the weights and covariance matrixes. \n",
    "\n",
    "    :param weights: an array that represents the weight of each asset\n",
    "    :param cov_matrix: a 2D matrix that represents the covariance between each asset \n",
    "    :return: variance of the portfolio\n",
    "    \"\"\"\n",
    "    weights_col = weights.reshape(-1, 1) # Turns into column vector\n",
    "    port_var = np.dot(weights_col.transpose(), (np.dot(cov_matrix, weights_col))) # Doing dot product \n",
    "    return port_var[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is what runs the primary function\n",
    "\n",
    "# Primary minimization, there is bounds in this \n",
    "def primary_minimization(cov_matrix):\n",
    "    \"\"\"     \n",
    "    primary_minimization is the function that finds the weightings that result in the mimimum variance. \n",
    "    It performs this using scipy optimization. This perimary version does not consider bounds. \n",
    "\n",
    "    :param cov_matrix: a 2D matrix that represents the covariance between each asset \n",
    "    :return: returns the minimum variance and the weightings associated with that\n",
    "    \"\"\"\n",
    "    num_assets = cov_matrix.shape[0]\n",
    "    initial_weight = [1/num_assets] * num_assets # The initial guess of the weights\n",
    "\n",
    "    constraint = {\n",
    "        'type':'eq', # Constraint type is equality\n",
    "        'fun': lambda w: sum(w) - 1 # The function's weight's must sum to 1\n",
    "        }\n",
    "    \n",
    "    weight_bounds = [(0, 1)] * num_assets # Does not allow short selling\n",
    "    \n",
    "    # Finds the resilt of the minimization of the port_variance function, using the initial guess, keeping the cov_matrix constant using the SLSQP method, and with the above listed constraint\n",
    "    result = minimize(fun=port_variance, x0=initial_weight, args=(cov_matrix,), method='SLSQP', bounds=weight_bounds, constraints=constraint)\n",
    "    return result.fun, result.x\n",
    "\n",
    "pd_cov_matrix = primary_calculations['Covariance']\n",
    "numpy_cov_matrix = pd_cov_matrix.to_numpy() # Matrix of covariances of assets\n",
    "primary_var, primary_weights = primary_minimization(numpy_cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondary Optimization logic: Let n be the size of the tickers, we now have an optimized weighting for those n stocks\n",
    "We want to find the most optimal set up of 10-25 stocks out of those n. To do so we will try every combination, however if we wanted to brute force from those n stocks it'd take an absurd amount of compute. Instead we will take into the fact that we have the weightings of the (unconstrained) optimization. The higher the weighting of an asset, the more important it is to the minimizing the  variance, thus we will sort the n-optimized assets from highest to lowest weighting. Starting from the top we will then build a 10-25 asset size portfolio and calculate the variance of each portfolio, finding the one with the least variance. \n",
    "\n",
    "We must also consider the fact that each portfolio has restraints, aka the min/max weighting of one stock, the max amount of sectors, and the mkt caps\n",
    "In regards to the weighting rules, those can be implemented via scipy's minimization constraints, making all weightings are in a certain range\n",
    "In regards to the max amount of sectors, when building the portfolios we will keep count of the sectors, if any sector exceeds a certain amount such that are over represented, we skip an asset and move on\n",
    "In regards to the small and large mkt cap, we can check after building the portfolio, if one of them is missing we can delete the lowest weighted (least important) asset and then add in a new asset from the list that satisfies the missing mkt cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The secondary optimization that includes the bounds \n",
    "def secondary_minimization(cov_matrix):\n",
    "    \"\"\"     \n",
    "    secondary_minimization is the function that finds the weightings that result in the mimimum variance while considering the bounds.\n",
    "    That is, it ensures the weightings \n",
    "\n",
    "    :param cov_matrix: a 2D matrix that represents the covariance between each asset \n",
    "    :return: returns the minimum variance and the weightings associated with that\n",
    "    \"\"\"\n",
    "    num_assets = len(cov_matrix[0]) \n",
    "    initial_weight = [1/num_assets] * num_assets # The initial guess of the weights\n",
    "\n",
    "    min_weight = (100/(2*num_assets))/100 # Do not need to include portfolio value, because 1 is the portfolio value (and sum of weights)\n",
    "    max_weight = 0.15 # Same as above\n",
    "\n",
    "    constraint = {\n",
    "        'type':'eq', # Constraint type is equality\n",
    "        'fun': lambda w: sum(w) - 1 # The function's weight's must sum to 1\n",
    "        }\n",
    "    \n",
    "    weight_bounds = [(min_weight, max_weight)] * num_assets\n",
    "    \n",
    "    # Finds the resilt of the minimization of the port_variance function, using the initial guess, keeping the cov_matrix constant using the SLSQP method, and with the above listed constraint\n",
    "    result = minimize(fun=port_variance, x0=initial_weight, args=(cov_matrix,), method='SLSQP', bounds = weight_bounds, constraints=constraint)\n",
    "    return result.fun, result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Currency</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DG</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>USD</td>\n",
       "      <td>22384783360</td>\n",
       "      <td>0.049195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FTS.TO</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>CAD</td>\n",
       "      <td>36722364416</td>\n",
       "      <td>0.037503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CME</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>USD</td>\n",
       "      <td>98476187648</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DUK</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>USD</td>\n",
       "      <td>95496806400</td>\n",
       "      <td>0.036014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEP</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>USD</td>\n",
       "      <td>64681492480</td>\n",
       "      <td>0.036006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USD</td>\n",
       "      <td>300678283264</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>CTAS</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>USD</td>\n",
       "      <td>74868211712</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>C</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>USD</td>\n",
       "      <td>181696626688</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>BABA</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>USD</td>\n",
       "      <td>364890390528</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USD</td>\n",
       "      <td>176200712192</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker              Sector Currency     MarketCap    weight\n",
       "0        DG  Consumer Defensive      USD   22384783360  0.049195\n",
       "1    FTS.TO           Utilities      CAD   36722364416  0.037503\n",
       "2       CME  Financial Services      USD   98476187648  0.037267\n",
       "3       DUK           Utilities      USD   95496806400  0.036014\n",
       "4       AEP           Utilities      USD   64681492480  0.036006\n",
       "..      ...                 ...      ...           ...       ...\n",
       "127    CSCO          Technology      USD  300678283264  0.000000\n",
       "128    CTAS         Industrials      USD   74868211712  0.000000\n",
       "129       C  Financial Services      USD  181696626688  0.000000\n",
       "130    BABA   Consumer Cyclical      USD  364890390528  0.000000\n",
       "131    QCOM          Technology      USD  176200712192  0.000000\n",
       "\n",
       "[132 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df['weight'] = primary_weights #Assume info_df holds the tickers, sector, market cap, etc and not the dates etc. We now add the weights.\n",
    "ordered_info_df = info_df.copy().sort_values('weight', ascending = False).reset_index(drop=True)\n",
    "\n",
    "ordered_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that creates a portfolio that matches the requirements\n",
    "\n",
    "# Determines all the indexes in a portfolio that are large cap stocks\n",
    "def is_lg_cap(portfolio):\n",
    "    \"\"\"\n",
    "     is_lg_cap determines all the indexes in a portfolio that are large cap stocks\n",
    "\n",
    "     :param portfolio: A list of Series objects that contain a stock's info \n",
    "     :return: A list of indexes of ticker's that are large cap\n",
    "     \"\"\"\n",
    "    lg_cap = []\n",
    "    for i in range(len(portfolio)):\n",
    "        if portfolio[i]['MarketCap'] > 10_000_000_000:\n",
    "            lg_cap.append(i)\n",
    "    return lg_cap\n",
    "\n",
    "# Determines all the indexes in a portfolio that are small cap stocks\n",
    "def is_sm_cap(portfolio):\n",
    "    \"\"\"\n",
    "     is_sm_cap determines all the indexes in a portfolio that are small cap stocks\n",
    "\n",
    "     :param portfolio: A list of Series objects that contain a stock's info \n",
    "     :return: A list of indexes of ticker's that are small cap\n",
    "     \"\"\"\n",
    "    sm_cap = []\n",
    "    for i in range(len(portfolio)):\n",
    "        if portfolio[i]['MarketCap'] < 2_000_000_000:\n",
    "            sm_cap.append(i)\n",
    "    return sm_cap\n",
    "\n",
    "# Determines if an individual stock is a large market cap\n",
    "def is_lg(row):\n",
    "    return row['MarketCap'] > 10_000_000_000\n",
    "\n",
    "# Determines if an individual stock is a small market cap\n",
    "def is_sm(row):\n",
    "    return row['MarketCap'] < 2_000_000_000\n",
    "\n",
    "# Determines the index of the least important stock. Least important in this case is the one with the lowest weighting in the ordered list, but\n",
    "# if the least important is either the ONLY SMALL or LARGE cap stock then the second least important stock is now designated the least important\n",
    "def find_least_imp(portfolio, lg_indxs, sm_indxs):\n",
    "    \"\"\" \n",
    "    find_least_imp Determines the index of the least important stock. Least important in this case is the one with the lowest weighting in the ordered list, but \n",
    "    if the least important is either the ONLY SMALL or LARGE cap stock then the second least important stock is now designated the least important\n",
    "\n",
    "    :param portfolio: A list of stock data in Series format\n",
    "    :param lg_indxs: A list of all indexes that hold large cap stocks\n",
    "    :param sm_indxs: A list of all indexes that hold small cap stocks\n",
    "    :return: integer that represents the index that is desginated least important\n",
    "    \"\"\"\n",
    "\n",
    "    only_large_idx = None\n",
    "    only_small_idx = None\n",
    "\n",
    "    # Determines the protected indexes\n",
    "    if len(lg_indxs) == 1:\n",
    "        only_large_idx = lg_indxs[0]\n",
    "    if len(sm_indxs) == 1:\n",
    "        only_small_idx = sm_indxs[0]\n",
    "\n",
    "    for i in range(len(portfolio) - 1, -1, -1):\n",
    "        if i != only_large_idx and i != only_small_idx:\n",
    "            return i\n",
    "\n",
    "def valid_port_check(ticker_list):\n",
    "    \"\"\"\n",
    "    valid_port_check checks if a portfolio fits all sector and weighting constraints\n",
    "\n",
    "    :param ticker_list: A list of ticker names\n",
    "    :return: Boolean value depending on if its true or not\n",
    "    \"\"\"\n",
    "    portfolio = [] # Will be a list of Series\n",
    "    port_sectors = []\n",
    "    max_sector_num = int(len(ticker_list) * 0.4)\n",
    "\n",
    "    # Creates preliminary portfolio \n",
    "    for i in range(len(ticker_list)):\n",
    "        cur = ordered_info_df[ordered_info_df[\"Ticker\"] == ticker_list[i]].iloc[0]\n",
    "        cur_sector = cur['Sector']\n",
    "        portfolio.append(cur)\n",
    "        port_sectors.append(cur_sector)\n",
    "    \n",
    "    for s in port_sectors:\n",
    "        if ((port_sectors.count(s)) > max_sector_num):\n",
    "            return False\n",
    "\n",
    "    num_lg = len(is_lg_cap(portfolio))\n",
    "    num_sm = len(is_sm_cap(portfolio))\n",
    "    if (num_lg == 0 or num_sm == 0):  \n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# Creates a portfolio that is valid \n",
    "def create_portfolio(size):\n",
    "    \"\"\" \n",
    "    create_portfolio creates a valid portfolio of a certain size\n",
    "\n",
    "    :param size: the size of the portfolio\n",
    "    :return: a list of tickers that are in the portfolio, or none if it cannot create a portfolio that satisfies all requirements\n",
    "    \"\"\"\n",
    "\n",
    "    portfolio = [] # Will be a list of Series\n",
    "    port_sectors = []\n",
    "    i = 0\n",
    "    max_sector_num = int(size * 0.4)\n",
    "    ticker_only = []\n",
    "    \n",
    "    # Creates preliminary portfolio \n",
    "    while len(portfolio) < size:\n",
    "        if i >= len(ordered_info_df):\n",
    "            return None\n",
    "        cur = ordered_info_df.iloc[i]\n",
    "        cur_sector = cur['Sector']\n",
    "\n",
    "        # Ensures that no sector is above max weight\n",
    "        if (port_sectors.count(cur_sector) < max_sector_num):\n",
    "            portfolio.append(cur)\n",
    "            port_sectors.append(cur_sector)\n",
    "        i += 1\n",
    "\n",
    "    lg_idxs = is_lg_cap(portfolio)\n",
    "    sm_idxs = is_sm_cap(portfolio)\n",
    "\n",
    "    # Fixes the no large market cap issue\n",
    "    while len(lg_idxs) == 0: \n",
    "        replaced = find_least_imp(portfolio, lg_idxs, sm_idxs)\n",
    "        if i >= len(ordered_info_df):\n",
    "            return None\n",
    "        cur = ordered_info_df.iloc[i]\n",
    "        cur_sector = cur['Sector']\n",
    "\n",
    "        temp_sectors = port_sectors.copy()\n",
    "        temp_sectors.pop(replaced)\n",
    "        \n",
    "        if (is_lg(cur)) and (temp_sectors.count(cur_sector) < max_sector_num):\n",
    "            portfolio[replaced] = cur\n",
    "            port_sectors[replaced] = cur_sector\n",
    "\n",
    "            lg_idxs = is_lg_cap(portfolio)\n",
    "            sm_idxs = is_sm_cap(portfolio)\n",
    "        i += 1\n",
    "\n",
    "    # Fixes the no small market cap issues\n",
    "    while len(sm_idxs) == 0: \n",
    "        replaced = find_least_imp(portfolio, lg_idxs, sm_idxs)\n",
    "        if i >= len(ordered_info_df):\n",
    "            return None\n",
    "        cur = ordered_info_df.iloc[i]\n",
    "        cur_sector = cur['Sector']\n",
    "\n",
    "        temp_sectors = port_sectors.copy()\n",
    "        temp_sectors.pop(replaced)\n",
    "        \n",
    "        if (is_sm(cur)) and (temp_sectors.count(cur_sector) < max_sector_num):\n",
    "            portfolio[replaced] = cur\n",
    "            port_sectors[replaced] = cur_sector\n",
    "\n",
    "            lg_idxs = is_lg_cap(portfolio)\n",
    "            sm_idxs = is_sm_cap(portfolio)\n",
    "        i += 1\n",
    "    \n",
    "    for stock in portfolio:\n",
    "        ticker_name = stock[\"Ticker\"]\n",
    "        ticker_only.append(ticker_name)\n",
    "    \n",
    "    return ticker_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest variance found is 7.889821209706994e-05 which is determined from the following portfolio: ['DG', 'FTS.TO', 'CME', 'DUK', 'AEP', 'EXC', 'ENB.TO', 'WN.TO', 'BNS.TO', 'UL', 'BB.TO', 'BTI', 'LMT', 'KO', 'T.TO', 'SLF.TO', 'BCE.TO', 'COST', 'ATD.TO', 'TRP.TO', 'GOOG', 'WCN.TO', 'RY.TO', 'NA.TO', 'KITS.TO'], at the following weights [0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04\n",
      " 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04].\n"
     ]
    }
   ],
   "source": [
    "# Code that creates the portfolio of 10-25, and then sees which one is the most optimal \n",
    "\n",
    "all_ports = []\n",
    "all_variance = []\n",
    "all_weights = []\n",
    "count = 0\n",
    "while (count + 10) < 26:\n",
    "    port = create_portfolio(count+10)\n",
    "    if port is None:\n",
    "        print(f\"Failed to build portfolio of size {count+10}, skipping.\")\n",
    "        count += 1\n",
    "        continue\n",
    "\n",
    "    all_ports.append(port)\n",
    "\n",
    "    temp_cov = get_calculations(all_ports[count], returns_start, returns_end)\n",
    "    cov_np = temp_cov['Covariance'].to_numpy()\n",
    "    temp_var, temp_weights = secondary_minimization(cov_np)\n",
    "\n",
    "    all_variance.append(temp_var)\n",
    "    all_weights.append(temp_weights)\n",
    "    count += 1\n",
    "\n",
    "if not all_variance:\n",
    "    print(\"No valid portfolios were generated for some reason. Please check ticker csv.\")\n",
    "else:\n",
    "    smallest_var = min(all_variance)\n",
    "    index = all_variance.index(smallest_var)\n",
    "    target = [smallest_var, all_ports[index], all_weights[index]]\n",
    "    print(f\"The smallest variance found is {target[0]} which is determined from the following portfolio: {target[1]}, at the following weights {target[2]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_prices_and_rate(tickers, target_date, end_date):\n",
    "    \"\"\"\n",
    "    get_close_prices_and_rate finds the closing price of tickers on a date, and the exchange rate on a date\n",
    "\n",
    "    :param tickers: list of tickers\n",
    "    :param target_data: the day of price we want, normally most recent business day\n",
    "    :param end_date: the day after, as yfinance is not inclusive\n",
    "    :return: a Series that contains the target days close price\n",
    "    :return: the USD to CAD exchange rate\n",
    "    \"\"\"\n",
    "    data = yf.download(tickers, start=target_date, end=end_date)[\"Close\"]\n",
    "    close_prices = data.iloc[0]\n",
    "\n",
    "    exchange_rate = yf.download(\"CAD=X\", start=target_date, end=end_date)[\"Close\"]\n",
    "    exchange_rate = exchange_rate.iloc[0]\n",
    "\n",
    "    return close_prices, exchange_rate.item()\n",
    "\n",
    "def purchase_flat_fee(df, budget, exchange_rate):\n",
    "    \"\"\"\n",
    "    purchase_flat_fee transforms a Dataframe to include the amount of shares bought with a flat fee, and the value of that\n",
    "\n",
    "    :param df: The Dataframe that will be transformed\n",
    "    :param budget: An Integer representing the budget\n",
    "    :param exchange_rate: A series of the USD-CAD exchange rate\n",
    "    :return: Transformed Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"Shares Bought Flat Fee\"] = (df[\"Weight\"] * (budget - (2.5*exchange_rate))) / df[\"Price\"]\n",
    "    df[\"Flat Fee Worth\"] = df[\"Shares Bought Flat Fee\"] * df[\"Price\"]\n",
    "\n",
    "    return df \n",
    "\n",
    "def purchase_variable_fee(df, budget, exchange_rate):\n",
    "    \"\"\"\n",
    "    purchase_variable_fee transforms a Dataframe to include the amount of shares bought with the share-dependent rate\n",
    "\n",
    "    :param df: The Dataframe that will be transformed\n",
    "    :param budget: An Integer representing the budget\n",
    "    :param exchange_rate: A series of the USD-CAD exchange rate\n",
    "    :return: Transformed Dataframe\n",
    "    \"\"\"\n",
    "    df[\"Shares w/o Fee\"] = (df[\"Weight\"] * budget) / df[\"Price\"]\n",
    "    total_shares = df[\"Shares w/o Fee\"].sum()\n",
    "    \n",
    "    variable_fee_usd = total_shares * 0.001\n",
    "    variable_fee_cad = variable_fee_usd * exchange_rate\n",
    "\n",
    "    adjusted_budget = budget - variable_fee_cad\n",
    "    df[\"Shares Bought Variable Fee\"] = (df[\"Weight\"] * adjusted_budget) / df[\"Price\"]\n",
    "    df[\"Variable Fee Worth\"] = df[\"Shares Bought Variable Fee\"] * df[\"Price\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "def ideal_shares(df):\n",
    "    \"\"\" \n",
    "    ideal_shares determines which fee strategy, flat or variable, is the most optimal and transforms Dataframe accordingly\n",
    "\n",
    "    :param df: The Dataframe that will be transformed\n",
    "    :return: Transformed Dataframe\n",
    "    \"\"\"\n",
    "    sum_flat_fee = df[\"Flat Fee Worth\"].sum()\n",
    "    sum_variable_fee = df[\"Variable Fee Worth\"].sum()\n",
    "\n",
    "    if (sum_flat_fee < sum_variable_fee):\n",
    "        df.drop([\"Shares Bought Flat Fee\", \"Flat Fee Worth\", \"Shares w/o Fee\"], axis=1, inplace=True)\n",
    "        df.rename(columns={\"Shares Bought Variable Fee\":\"Shares\", \"Variable Fee Worth\":\"Value\"}, inplace=True)\n",
    "    else:\n",
    "        df.drop([\"Shares Bought Variable Fee\", \"Variable Fee Worth\", \"Shares w/o Fee\"], axis=1, inplace=True)\n",
    "        df.rename(columns={\"Shares Bought Flat Fee\":\"Shares\", \"Flat Fee Worth\":\"Value\"}, inplace=True)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def add_currency(df_small, df_large):\n",
    "    \"\"\" \n",
    "    add_currency adds the currency type onto the Dataframe\n",
    "\n",
    "    :param df_small: The Dataframe that holds the shares bought\n",
    "    :param_df_large: The Dataframe the holds the Currency's\n",
    "    :return: Transformed Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_with_currency = df_small.merge(df_large[[\"Ticker\", \"Currency\"]], on=\"Ticker\", how=\"left\")\n",
    "    return df_with_currency\n",
    "\n",
    "def convert_closing(df, exchange_rate):\n",
    "    \"\"\"\n",
    "    convert_closing converts the price of any stock thats in USD to CAD\n",
    "\n",
    "    :param df: Dataframe to be transformed\n",
    "    :param exchange_rate: The USD-CAD rate\n",
    "    :return: Dataframe with converted prices\n",
    "    \"\"\"\n",
    "\n",
    "    df.loc[df[\"Currency\"] == \"USD\", \"Price\"] = df[\"Price\"] * exchange_rate\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yello\\AppData\\Local\\Temp\\ipykernel_23748\\1056367655.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=target_date, end=end_date)[\"Close\"]\n",
      "[*********************100%***********************]  25 of 25 completed\n",
      "C:\\Users\\yello\\AppData\\Local\\Temp\\ipykernel_23748\\1056367655.py:14: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  exchange_rate = yf.download(\"CAD=X\", start=target_date, end=end_date)[\"Close\"]\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the weights is 1.0, the sum of the shares is 17500.606131598044, the sum of the values is 999996.4873749018.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df = pd.DataFrame({\n",
    "    \"Ticker\": target[1],\n",
    "    \"Weight\": target[2]\n",
    "})\n",
    "\n",
    "target_date = \"2025-11-18\" #Example\n",
    "end_date = \"2025-11-19\" #Example\n",
    "closing, usd_cad_rate = get_close_prices_and_rate(target[1], target_date, end_date)\n",
    "temp_df[\"Price\"] = closing.to_numpy()\n",
    "temp_df = add_currency(temp_df,ordered_info_df)\n",
    "temp_df_cad = convert_closing(temp_df, usd_cad_rate)\n",
    "temp_df_cad = purchase_flat_fee(temp_df_cad, 1_000_000, usd_cad_rate)\n",
    "temp_df_cad = purchase_variable_fee(temp_df_cad, 1_000_000, usd_cad_rate)\n",
    "Portfolio_Final = ideal_shares(temp_df_cad)\n",
    "\n",
    "Stocks_Final = Portfolio_Final.copy()\n",
    "Stocks_Final = Stocks_Final.drop(columns=[\"Currency\", \"Weight\", \"Price\"], errors=\"ignore\")\n",
    "#Stocks_Final.to_csv(\"Stocks_Group_15.csv\", index=False)\n",
    "\n",
    "sum_weight = Portfolio_Final[\"Weight\"].sum() # Doesn't return 1 properly because floats can't sum to exact integers\n",
    "sum_shares = Portfolio_Final[\"Shares\"].sum()\n",
    "sum_value = Portfolio_Final[\"Value\"].sum()\n",
    "print(f\"The sum of the weights is {sum_weight}, the sum of the shares is {sum_shares}, the sum of the values is {sum_value}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Price</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DG</td>\n",
       "      <td>0.04</td>\n",
       "      <td>173.537733</td>\n",
       "      <td>USD</td>\n",
       "      <td>230.496611</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FTS.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>69.510002</td>\n",
       "      <td>CAD</td>\n",
       "      <td>575.454730</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CME</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.458401</td>\n",
       "      <td>USD</td>\n",
       "      <td>4729.009479</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DUK</td>\n",
       "      <td>0.04</td>\n",
       "      <td>45.256660</td>\n",
       "      <td>USD</td>\n",
       "      <td>883.844700</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEP</td>\n",
       "      <td>0.04</td>\n",
       "      <td>133.198748</td>\n",
       "      <td>USD</td>\n",
       "      <td>300.302068</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EXC</td>\n",
       "      <td>0.04</td>\n",
       "      <td>77.081046</td>\n",
       "      <td>USD</td>\n",
       "      <td>518.932495</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENB.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>279.279999</td>\n",
       "      <td>CAD</td>\n",
       "      <td>143.224934</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WN.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>895.080017</td>\n",
       "      <td>CAD</td>\n",
       "      <td>44.688585</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BNS.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>103.330002</td>\n",
       "      <td>CAD</td>\n",
       "      <td>387.107895</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UL</td>\n",
       "      <td>0.04</td>\n",
       "      <td>173.945199</td>\n",
       "      <td>USD</td>\n",
       "      <td>229.956674</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BB.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>67.510002</td>\n",
       "      <td>CAD</td>\n",
       "      <td>592.502714</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BTI</td>\n",
       "      <td>0.04</td>\n",
       "      <td>65.166222</td>\n",
       "      <td>USD</td>\n",
       "      <td>613.812771</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LMT</td>\n",
       "      <td>0.04</td>\n",
       "      <td>102.119037</td>\n",
       "      <td>USD</td>\n",
       "      <td>391.698361</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>400.383047</td>\n",
       "      <td>USD</td>\n",
       "      <td>99.903979</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>CAD</td>\n",
       "      <td>2969.551500</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SLF.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>71.220001</td>\n",
       "      <td>CAD</td>\n",
       "      <td>561.638006</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BCE.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>474.720001</td>\n",
       "      <td>CAD</td>\n",
       "      <td>84.259899</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COST</td>\n",
       "      <td>0.04</td>\n",
       "      <td>226.971774</td>\n",
       "      <td>USD</td>\n",
       "      <td>176.232748</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ATD.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>208.380005</td>\n",
       "      <td>CAD</td>\n",
       "      <td>191.956323</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TRP.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>82.820000</td>\n",
       "      <td>CAD</td>\n",
       "      <td>482.973432</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.04</td>\n",
       "      <td>26.695951</td>\n",
       "      <td>USD</td>\n",
       "      <td>1498.349314</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WCN.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>75.709999</td>\n",
       "      <td>CAD</td>\n",
       "      <td>528.329943</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RY.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>59.389999</td>\n",
       "      <td>CAD</td>\n",
       "      <td>673.511701</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NA.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>240.669998</td>\n",
       "      <td>CAD</td>\n",
       "      <td>166.202102</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KITS.TO</td>\n",
       "      <td>0.04</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>CAD</td>\n",
       "      <td>426.665168</td>\n",
       "      <td>39999.859495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker  Weight       Price Currency       Shares         Value\n",
       "0        DG    0.04  173.537733      USD   230.496611  39999.859495\n",
       "1    FTS.TO    0.04   69.510002      CAD   575.454730  39999.859495\n",
       "2       CME    0.04    8.458401      USD  4729.009479  39999.859495\n",
       "3       DUK    0.04   45.256660      USD   883.844700  39999.859495\n",
       "4       AEP    0.04  133.198748      USD   300.302068  39999.859495\n",
       "5       EXC    0.04   77.081046      USD   518.932495  39999.859495\n",
       "6    ENB.TO    0.04  279.279999      CAD   143.224934  39999.859495\n",
       "7     WN.TO    0.04  895.080017      CAD    44.688585  39999.859495\n",
       "8    BNS.TO    0.04  103.330002      CAD   387.107895  39999.859495\n",
       "9        UL    0.04  173.945199      USD   229.956674  39999.859495\n",
       "10    BB.TO    0.04   67.510002      CAD   592.502714  39999.859495\n",
       "11      BTI    0.04   65.166222      USD   613.812771  39999.859495\n",
       "12      LMT    0.04  102.119037      USD   391.698361  39999.859495\n",
       "13       KO    0.04  400.383047      USD    99.903979  39999.859495\n",
       "14     T.TO    0.04   13.470000      CAD  2969.551500  39999.859495\n",
       "15   SLF.TO    0.04   71.220001      CAD   561.638006  39999.859495\n",
       "16   BCE.TO    0.04  474.720001      CAD    84.259899  39999.859495\n",
       "17     COST    0.04  226.971774      USD   176.232748  39999.859495\n",
       "18   ATD.TO    0.04  208.380005      CAD   191.956323  39999.859495\n",
       "19   TRP.TO    0.04   82.820000      CAD   482.973432  39999.859495\n",
       "20     GOOG    0.04   26.695951      USD  1498.349314  39999.859495\n",
       "21   WCN.TO    0.04   75.709999      CAD   528.329943  39999.859495\n",
       "22    RY.TO    0.04   59.389999      CAD   673.511701  39999.859495\n",
       "23    NA.TO    0.04  240.669998      CAD   166.202102  39999.859495\n",
       "24  KITS.TO    0.04   93.750000      CAD   426.665168  39999.859495"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Portfolio_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     41\u001b[39m             optimal_weights = current_weights\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m optimal_port, optimal_var, optimal_weights\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m optimal_portfolio, optimal_variance, optimal_weights = \u001b[43mcreate_optimal_portfolio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mordered_ticker_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mcreate_optimal_portfolio\u001b[39m\u001b[34m(ordered_ticker_list)\u001b[39m\n\u001b[32m     27\u001b[39m optimal_weights = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m potential_portfolios:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     current_port, current_var, current_weights = \u001b[43mcreate_portfolio_combs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Current portfolio failed the requirements\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m current_port \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcreate_portfolio_combs\u001b[39m\u001b[34m(ticker_list)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_portfolio_combs\u001b[39m(ticker_list):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mvalid_port_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mvalid_port_check\u001b[39m\u001b[34m(ticker_list)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Creates preliminary portfolio \u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ticker_list)):\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     cur = \u001b[43mordered_info_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mordered_info_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTicker\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.iloc[\u001b[32m0\u001b[39m]\n\u001b[32m     79\u001b[39m     cur_sector = cur[\u001b[33m'\u001b[39m\u001b[33mSector\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     80\u001b[39m     portfolio.append(cur)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yello\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\frame.py:4104\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4102\u001b[39m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m4104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4106\u001b[39m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[32m   4107\u001b[39m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[32m   4108\u001b[39m is_single_key = \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yello\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\frame.py:4166\u001b[39m, in \u001b[36mDataFrame._getitem_bool_array\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   4165\u001b[39m indexer = key.nonzero()[\u001b[32m0\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m4166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yello\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\generic.py:4175\u001b[39m, in \u001b[36mNDFrame._take_with_is_copy\u001b[39m\u001b[34m(self, indices, axis)\u001b[39m\n\u001b[32m   4164\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   4165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis = \u001b[32m0\u001b[39m) -> Self:\n\u001b[32m   4166\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4167\u001b[39m \u001b[33;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[32m   4168\u001b[39m \u001b[33;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4173\u001b[39m \u001b[33;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[32m   4174\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4175\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4176\u001b[39m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[32m   4177\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result._get_axis(axis).equals(\u001b[38;5;28mself\u001b[39m._get_axis(axis)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yello\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\generic.py:4155\u001b[39m, in \u001b[36mNDFrame.take\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4150\u001b[39m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[32m   4151\u001b[39m     indices = np.arange(\n\u001b[32m   4152\u001b[39m         indices.start, indices.stop, indices.step, dtype=np.intp\n\u001b[32m   4153\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4159\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n\u001b[32m   4161\u001b[39m     \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mtake\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4162\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yello\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:913\u001b[39m, in \u001b[36mBaseBlockManager.take\u001b[39m\u001b[34m(self, indexer, axis, verify)\u001b[39m\n\u001b[32m    910\u001b[39m indexer = maybe_convert_indices(indexer, n, verify=verify)\n\u001b[32m    912\u001b[39m new_labels = \u001b[38;5;28mself\u001b[39m.axes[axis].take(indexer)\n\u001b[32m--> \u001b[39m\u001b[32m913\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yello\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:707\u001b[39m, in \u001b[36mBaseBlockManager.reindex_indexer\u001b[39m\u001b[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[39m\n\u001b[32m    699\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    700\u001b[39m         indexer,\n\u001b[32m    701\u001b[39m         fill_value=fill_value,\n\u001b[32m    702\u001b[39m         only_slice=only_slice,\n\u001b[32m    703\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    704\u001b[39m     )\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    706\u001b[39m     new_blocks = [\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    714\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks\n\u001b[32m    715\u001b[39m     ]\n\u001b[32m    717\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    718\u001b[39m new_axes[axis] = new_axis\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yello\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1373\u001b[39m, in \u001b[36mBlock.take_nd\u001b[39m\u001b[34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[39m\n\u001b[32m   1370\u001b[39m     allow_fill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1372\u001b[39m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m new_values = \u001b[43malgos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[32m   1378\u001b[39m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[32m   1381\u001b[39m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yello\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[39m, in \u001b[36mtake_nd\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\u001b[32m    116\u001b[39m arr = np.asarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yello\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[39m, in \u001b[36m_take_nd_ndarray\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    157\u001b[39m     out = np.empty(out_shape, dtype=dtype)\n\u001b[32m    159\u001b[39m func = _get_take_nd_function(\n\u001b[32m    160\u001b[39m     arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n\u001b[32m    161\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[32m    165\u001b[39m     out = out.T\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Third Optimization --- #\n",
    "\n",
    "# Make a list of the top 30 most important stocks\n",
    "ordered_ticker_list = get_ticker_list(ordered_info_df)\n",
    "ordered_ticker_list = ordered_ticker_list[0:30]\n",
    "\n",
    "\n",
    "def create_portfolio_combs(ticker_list):\n",
    "    if not valid_port_check(ticker_list):\n",
    "        return None, None, None\n",
    "    else:\n",
    "        temp_cov2 = get_calculations(ticker_list, returns_start, returns_end)\n",
    "        cov_np2 = temp_cov2['Covariance'].to_numpy()\n",
    "        temp_var2, temp_weights2 = secondary_minimization(cov_np2)\n",
    "\n",
    "        # Returns the inputted list, the variance, and a list of the weights\n",
    "        return ticker_list, temp_var2, temp_weights2\n",
    "\n",
    "\n",
    "def create_optimal_portfolio(ordered_ticker_list):\n",
    "    # Create list of every possible portfolio\n",
    "    potential_portfolios = list(itr.combinations(ordered_ticker_list, 25))\n",
    "\n",
    "    # Initialize the optimal portfolio data\n",
    "    optimal_port = None\n",
    "    optimal_var = float(\"inf\")       # Infinitely high float\n",
    "    optimal_weights = None\n",
    "\n",
    "    for i in potential_portfolios:\n",
    "        current_port, current_var, current_weights = create_portfolio_combs(i)\n",
    "\n",
    "        # Current portfolio failed the requirements\n",
    "        if current_port is None:\n",
    "            continue # skip\n",
    "        \n",
    "        # If the current portfolio has a lower variance than any previous ones\n",
    "        if current_var <= optimal_var:\n",
    "            # Set the optimal portfolio data to the current\n",
    "            optimal_port = current_port\n",
    "            optimal_var = current_var\n",
    "            optimal_weights = current_weights\n",
    "\n",
    "    return optimal_port, optimal_var, optimal_weights\n",
    "\n",
    "\n",
    "optimal_portfolio, optimal_variance, optimal_weights = create_optimal_portfolio(ordered_ticker_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Insert Names Here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
